{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ShopAssist AI**"
      ],
      "metadata": {
        "id": "XxesLgJpGyBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Background**\n",
        "In today's digital age, online shopping has become the go-to option for many consumers. However, the overwhelming number of choices and the lack of personalized assistance can make the shopping experience daunting. To address this, we have developed ShopAssist AI, a chatbot that combines the power of large language models and rule-based functions to ensure accurate and reliable information delivery."
      ],
      "metadata": {
        "id": "SqiN3M5mG0bY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**"
      ],
      "metadata": {
        "id": "_CETFfFCHKid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a dataset containing information about laptops (product names, specifications, descriptions, etc.), build a chatbot that parses the dataset and provides accurate laptop recommendations based on user requirements."
      ],
      "metadata": {
        "id": "9T2eAuVvHDnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install OpenAI library\n",
        "!pip install -U -q openai tenacity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZBeQm8pJ5WL",
        "outputId": "0d399a5a-0bbb-4650-adb3-e334d215ed06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBLaC8dQKE1Z",
        "outputId": "16443f65-c198-4fbe-d22f-4f68e6a2aaa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "# Set the display width to control the output width\n",
        "pd.set_option('display.width', 100)\n",
        "# Read the dataset and read the Laptop Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/laptop_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "t3QFUTeCHjZA",
        "outputId": "487a624f-5c39-48b4-b829-0bd4e1b81d0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Brand   Model Name Core CPU Manufacturer Clock Speed RAM Size Storage Type Display Type  \\\n",
              "0    Dell     Inspiron   i5            Intel     2.4 GHz      8GB          SSD          LCD   \n",
              "1     MSI         GL65   i7            Intel     2.6 GHz     16GB      HDD+SSD          IPS   \n",
              "2      HP    EliteBook   i7            Intel     2.8 GHz     16GB          SSD          LED   \n",
              "3  Lenovo      IdeaPad   i3            Intel     2.1 GHz      8GB          HDD           TN   \n",
              "4    ASUS  ZenBook Pro   i9            Intel     3.1 GHz     64GB          SSD         OLED   \n",
              "\n",
              "  Display Size Graphics Processor Screen Resolution          OS Laptop Weight    Special Features  \\\n",
              "0        15.6\"          Intel UHD         1920x1080  Windows 10        2.5 kg    Backlit Keyboard   \n",
              "1        15.6\"         NVIDIA GTX         1920x1080  Windows 10        2.3 kg        RGB Keyboard   \n",
              "2          14\"          Intel UHD         1920x1080  Windows 11        1.5 kg  Fingerprint Sensor   \n",
              "3        15.6\"          Intel UHD          1366x768  Windows 10        2.2 kg         Dolby Audio   \n",
              "4        15.6\"         NVIDIA RTX         3840x2160  Windows 10        1.8 kg    NanoEdge Display   \n",
              "\n",
              "  Warranty Average Battery Life    Price                                        Description  \n",
              "0   1 year              6 hours   35,000  The Dell Inspiron is a versatile laptop that c...  \n",
              "1  2 years              4 hours   55,000  The MSI GL65 is a high-performance laptop desi...  \n",
              "2  3 years              8 hours   90,000  The HP EliteBook is a premium laptop designed ...  \n",
              "3   1 year              5 hours   25,000  The Lenovo IdeaPad is a versatile laptop that ...  \n",
              "4  2 years              7 hours  200,000  The ASUS ZenBook Pro is a high-end laptop that...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2ad83ef-0aa0-4103-a728-f49b258c29dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Core</th>\n",
              "      <th>CPU Manufacturer</th>\n",
              "      <th>Clock Speed</th>\n",
              "      <th>RAM Size</th>\n",
              "      <th>Storage Type</th>\n",
              "      <th>Display Type</th>\n",
              "      <th>Display Size</th>\n",
              "      <th>Graphics Processor</th>\n",
              "      <th>Screen Resolution</th>\n",
              "      <th>OS</th>\n",
              "      <th>Laptop Weight</th>\n",
              "      <th>Special Features</th>\n",
              "      <th>Warranty</th>\n",
              "      <th>Average Battery Life</th>\n",
              "      <th>Price</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dell</td>\n",
              "      <td>Inspiron</td>\n",
              "      <td>i5</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.4 GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>LCD</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.5 kg</td>\n",
              "      <td>Backlit Keyboard</td>\n",
              "      <td>1 year</td>\n",
              "      <td>6 hours</td>\n",
              "      <td>35,000</td>\n",
              "      <td>The Dell Inspiron is a versatile laptop that c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MSI</td>\n",
              "      <td>GL65</td>\n",
              "      <td>i7</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.6 GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>HDD+SSD</td>\n",
              "      <td>IPS</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>NVIDIA GTX</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.3 kg</td>\n",
              "      <td>RGB Keyboard</td>\n",
              "      <td>2 years</td>\n",
              "      <td>4 hours</td>\n",
              "      <td>55,000</td>\n",
              "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HP</td>\n",
              "      <td>EliteBook</td>\n",
              "      <td>i7</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.8 GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>LED</td>\n",
              "      <td>14\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 11</td>\n",
              "      <td>1.5 kg</td>\n",
              "      <td>Fingerprint Sensor</td>\n",
              "      <td>3 years</td>\n",
              "      <td>8 hours</td>\n",
              "      <td>90,000</td>\n",
              "      <td>The HP EliteBook is a premium laptop designed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lenovo</td>\n",
              "      <td>IdeaPad</td>\n",
              "      <td>i3</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.1 GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>HDD</td>\n",
              "      <td>TN</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1366x768</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.2 kg</td>\n",
              "      <td>Dolby Audio</td>\n",
              "      <td>1 year</td>\n",
              "      <td>5 hours</td>\n",
              "      <td>25,000</td>\n",
              "      <td>The Lenovo IdeaPad is a versatile laptop that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ASUS</td>\n",
              "      <td>ZenBook Pro</td>\n",
              "      <td>i9</td>\n",
              "      <td>Intel</td>\n",
              "      <td>3.1 GHz</td>\n",
              "      <td>64GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>OLED</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>NVIDIA RTX</td>\n",
              "      <td>3840x2160</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>1.8 kg</td>\n",
              "      <td>NanoEdge Display</td>\n",
              "      <td>2 years</td>\n",
              "      <td>7 hours</td>\n",
              "      <td>200,000</td>\n",
              "      <td>The ASUS ZenBook Pro is a high-end laptop that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2ad83ef-0aa0-4103-a728-f49b258c29dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2ad83ef-0aa0-4103-a728-f49b258c29dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2ad83ef-0aa0-4103-a728-f49b258c29dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6dd8017-3832-4e56-a84f-73d644db23f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6dd8017-3832-4e56-a84f-73d644db23f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6dd8017-3832-4e56-a84f-73d644db23f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Apple\",\n          \"MSI\",\n          \"Acer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Inspiron\",\n          \"ENVY x360\",\n          \"ZenBook 13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Core\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"i7\",\n          \"Ryzen 5\",\n          \"i5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPU Manufacturer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Intel\",\n          \"AMD\",\n          \"Apple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clock Speed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2.9 GHz\",\n          \"2.6 GHz\",\n          \"1.6 GHz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"16GB\",\n          \"32GB\",\n          \"64GB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SSD\",\n          \"HDD+SSD\",\n          \"HDD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Display Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"IPS\",\n          \"PixelSense\",\n          \"LCD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Display Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"15.6\\\"\",\n          \"14\\\"\",\n          \"16\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Graphics Processor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NVIDIA GTX\",\n          \"Apple M1\",\n          \"Intel UHD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen Resolution\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1920x1080\",\n          \"1366x768\",\n          \"2560x1600\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Windows 11\",\n          \"Ubuntu\",\n          \"Linux\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Laptop Weight\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"2.5 kg\",\n          \"2.3 kg\",\n          \"2.1 kg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Special Features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Backlit Keyboard\",\n          \"Dual Cooling Fans\",\n          \"Fingerprint Reader\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Warranty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1 year\",\n          \"2 years\",\n          \"3 years\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Battery Life\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"14 hours\",\n          \"4 hours\",\n          \"10 hours\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"35,000\",\n          \"55,000\",\n          \"85,000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\\\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\",\n          \"The HP ENVY x360 is a versatile 2-in-1 convertible laptop that combines performance and flexibility. It features an Intel Core i7 processor running at 2.8 GHz, providing powerful processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage space. The laptop features a 15.6\\\" IPS display with a resolution of 1920x1080, delivering vibrant visuals and wide viewing angles. It comes with Intel Iris Xe integrated graphics for smooth graphics performance. Weighing 2.05 kg, it offers a good balance between portability and functionality. The laptop features a convertible design, allowing you to switch between laptop and tablet modes for enhanced versatility. With a one-year warranty and a battery life of up to 7 hours, the HP ENVY x360 offers reliability and endurance for everyday use. Priced at 80,000, it provides a versatile computing experience at an affordable price point.\",\n          \"The ASUS ZenBook 13 is a lightweight and powerful laptop that offers a premium computing experience. It is equipped with an Intel Core i7 processor running at 2.8 GHz, providing strong processing power for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and responsive performance along with ample storage capacity. The laptop features a 13.3\\\" NanoEdge display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing. It comes with Intel Iris Xe integrated graphics for smooth graphics performance. Weighing just 1.11 kg, it is incredibly lightweight and highly portable. The laptop features military-grade durability, ensuring durability and reliability. With a two-year warranty and an impressive battery life of up to 11 hours, the ASUS ZenBook 13 offers long-lasting performance and endurance. Priced at 95,000, it provides a premium experience for users seeking a powerful and lightweight laptop.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach**"
      ],
      "metadata": {
        "id": "gF2GKcm9Ik8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Conversation and Information Gathering:** The chatbot will utilize language models to understand and generate natural responses. Through a conversational flow, it will ask relevant questions to gather information about the user's requirements.\n",
        "\n",
        "2. **Information Extraction:** Once the essential information is collected, rule-based functions come into play, extracting top 3 laptops that best matches the user's needs.\n",
        "\n",
        "3. **Personalized Recommendation:** Leveraging this extracted information, the chatbot engages in further dialogue with the user, efficiently addressing their queries and aiding them in finding the perfect laptop solution."
      ],
      "metadata": {
        "id": "8qyRrgxwInXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**System Design**"
      ],
      "metadata": {
        "id": "cge3tN6GI1Gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset:**\n",
        "We have a dataset laptop.csv where each row describes the features of a single laptop and also has a small description at the end. The chatbot that we build will leverage LLMs to parse this Description column and provide recommendations"
      ],
      "metadata": {
        "id": "ntyXkeVAI3hh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the overall flow of conversation for the ShopAssist Chatbot:\n",
        "\n",
        "The chatbot should ask a series of questions to\n",
        "\n",
        "1. Determine the user's requirments. For simplicity, we have used 6 features to encapsulate the user's needs. The 6 features are as follows:\n",
        "\n",
        "2. GPU intensity\n",
        "3. Display quality\n",
        "4. Portability\n",
        "5. Multitasking\n",
        "6. Processing speed\n",
        "7. Budget\n",
        "8. Confirm if the user's requirements have been correctly captured at the end.\n",
        "\n",
        "\n",
        "After that the chatbot lists down the top 3 products that are the most relevant, and engages in further conversation to help the user find the best one."
      ],
      "metadata": {
        "id": "LVBvyhS_JC1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Chatbot**"
      ],
      "metadata": {
        "id": "ZiUExv6C-rBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's go ahead and understand the system design for the chatbot.\n",
        "\n",
        "Chatbot_sys_design.png\n",
        "\n",
        "1. Stage 1\n",
        "\n",
        " *   Intent Clarity Layer\n",
        " *   Intent Confirmation Layer\n",
        "\n",
        "\n",
        "2. Stage 2\n",
        "\n",
        " *  Product Mapping Layer\n",
        " *  Product Information Extraction Layer\n",
        "\n",
        "3. Stage 3\n",
        "\n",
        " *  Product Recommendation Layer"
      ],
      "metadata": {
        "id": "EIoML-zw-ss0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Major functions behind the Chatbot**\n",
        "\n",
        "\n",
        "\n",
        "Let's now look at a brief overview of the major functions that form the chatbot. We'll take a deep dive later\n",
        "\n",
        "*   initialize_conversation(): This initializes the variable conversation with the system message.\n",
        "*   get_chat_completions(): This takes the ongoing conversation as the input and returns the response by the assistant\n",
        "*   moderation_check(): This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
        "*   intent_confirmation_layer(): This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget\n",
        "*   dictionary_present(): This function checks if the final understanding of user's profile is returned by the chatbot as a python dictionary or not. If there is a dictionary, it extracts the information as a Python dictionary.\n",
        "*   compare_laptops_with_user(): This function compares the user's profile with the different laptops and come back with the top 3 recommendations.\n",
        "*   initialize_conv_reco(): Initializes the recommendations conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "TMwXbIJ0_YtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next sections, we will look at how to write the code for the above functions."
      ],
      "metadata": {
        "id": "A4p3zSD7__2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation**"
      ],
      "metadata": {
        "id": "nJH8AG07AW7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the libraries\n",
        "\n",
        "Let's start by importing the libraries that we'll require for this project. Following are the ones:\n",
        "- openai\n",
        "- pandas\n",
        "- os, json, ast\n",
        "\n",
        "The api key is in a text file API_key.txt."
      ],
      "metadata": {
        "id": "mL0xp2tgAiIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B8Nz80qAnUS",
        "outputId": "242d377a-eeae-4f47-8c2a-fec2567f73b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.14)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q openai tenacity"
      ],
      "metadata": {
        "id": "yask0QCbAuje"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4tqvKhQBMc4",
        "outputId": "3480fc00-13d5-4e1c-ebb6-876006f3f92c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.35.14\n",
            "    Uninstalling openai-1.35.14:\n",
            "      Successfully uninstalled openai-1.35.14\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,json,ast\n",
        "import openai\n",
        "import pandas as pd\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt"
      ],
      "metadata": {
        "id": "EAYJSmSwBUZj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the API key\n",
        "openai.api_key = open(\"/content/drive/MyDrive/API_Key.txt\", \"r\").read().strip()"
      ],
      "metadata": {
        "id": "PYbPJA0pBb4v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing Intent Clarity and Intent Confirmation Layers**"
      ],
      "metadata": {
        "id": "RjrWoxYZ8bPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with the first part of the implementation - building the intent clarity and intent confirmation layers. As mentioned earlier, this layer helps in identifying the user requirements and passing it on to the product matching layer. Here are the functions that we would be using for building these layers:\n",
        "\n",
        "*  initialize_conversation(): This initializes the variable conversation with the system message. Using prompt engineering and chain of thought reasoning, the function will enable the chatbot to keep asking questions until the user requirements have been captured in a dictionary. It also includes Few Shot Prompting(sample conversation between the user and assistant) to align the model about user and assistant responses at each step."
      ],
      "metadata": {
        "id": "VNzHz96e8iAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "    example_user_req = {'GPU intensity': 'high','Display quality': 'high','Portability': 'low','Multitasking': 'high','Processing speed': 'high','Budget': '150000'}\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "\n",
        "    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\n",
        "    You need to ask relevant questions and understand the user profile by analysing the user's responses.\n",
        "    Your final objective is to fill the values for the different keys ('GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget') in the python dictionary and be confident of the values.\n",
        "    These key value pairs define the user's profile.\n",
        "    The python dictionary looks like this {{'GPU intensity': 'values','Display quality': 'values','Portability': 'values','Multitasking': 'values','Processing speed': 'values','Budget': 'values'}}\n",
        "    The values for all keys, except 'budget', should be 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    The value for 'budget' should be a numerical value extracted from the user's response.\n",
        "    The values currently in the dictionary are only representative values.\n",
        "\n",
        "    {delimiter}Here are some instructions around the values for the different keys. If you do not follow this, you'll be heavily penalised.\n",
        "    - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    - The value for 'budget' should be a numerical value extracted from the user's response.\n",
        "    - 'Budget' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range.\n",
        "    - Do not randomly assign values to any of the keys. The values need to be inferred from the user's response.\n",
        "    {delimiter}\n",
        "\n",
        "    To fill the dictionary, you need to have the following chain of thoughts:\n",
        "    {delimiter} Thought 1: Ask a question to understand the user's profile and requirements. \\n\n",
        "    If their primary use for the laptop is unclear. Ask another question to comprehend their needs.\n",
        "    You are trying to fill the values of all the keys ('GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget') in the python dictionary by understanding the user requirements.\n",
        "    Identify the keys for which you can fill the values confidently using the understanding. \\n\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    Answer \"Yes\" or \"No\" to indicate if you understand the requirements and have updated the values for the relevant keys. \\n\n",
        "    If yes, proceed to the next step. Otherwise, rephrase the question to capture their profile. \\n{delimiter}\n",
        "\n",
        "    {delimiter}Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn't in the previous step.\n",
        "    Remember the instructions around the values for the different keys. Ask questions you might have for all the keys to strengthen your understanding of the user's profile.\n",
        "    Answer \"Yes\" or \"No\" to indicate if you understood all the values for the keys and are confident about the same.\n",
        "    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\n",
        "    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.{delimiter}\n",
        "\n",
        "    {delimiter}Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\n",
        "    If you are not confident about any of the values, ask clarifying questions. {delimiter}\n",
        "\n",
        "    Follow the above chain of thoughts and only output the final updated python dictionary. \\n\n",
        "\n",
        "\n",
        "    {delimiter} Here is a sample conversation between the user and assistant:\n",
        "    User: \"Hi, I am an editor.\"\n",
        "    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\"\n",
        "    User: \"I primarily work with After Effects.\"\n",
        "    Assistant: \"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\"\n",
        "    User: \"Yes, sometimes I work with 4K videos as well.\"\n",
        "    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\"\n",
        "    User: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
        "    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"\n",
        "    User: \"my max budget is 1.5lakh inr\"\n",
        "    Assistant: \"{example_user_req}\"\n",
        "    {delimiter}\n",
        "\n",
        "    Start with a short welcome message and encourage the user to share their requirements.\n",
        "    \"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    return conversation"
      ],
      "metadata": {
        "id": "mGDG4hhd81xt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what does initialize_conversation() does. We have added a prefix debug_ to each of the variables so that we can play around with the inputs and outputs and it doesn't disturb the main function."
      ],
      "metadata": {
        "id": "fj-W0xFu8772"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation = initialize_conversation()\n",
        "print(debug_conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3-tkSL89EPp",
        "outputId": "7f5030e5-4413-40e8-f253-690b679a2d3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': '\\n\\n    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\\n    You need to ask relevant questions and understand the user profile by analysing the user\\'s responses.\\n    Your final objective is to fill the values for the different keys (\\'GPU intensity\\',\\'Display quality\\',\\'Portability\\',\\'Multitasking\\',\\'Processing speed\\',\\'Budget\\') in the python dictionary and be confident of the values.\\n    These key value pairs define the user\\'s profile.\\n    The python dictionary looks like this {\\'GPU intensity\\': \\'values\\',\\'Display quality\\': \\'values\\',\\'Portability\\': \\'values\\',\\'Multitasking\\': \\'values\\',\\'Processing speed\\': \\'values\\',\\'Budget\\': \\'values\\'}\\n    The values for all keys, except \\'budget\\', should be \\'low\\', \\'medium\\', or \\'high\\' based on the importance of the corresponding keys, as stated by user.\\n    The value for \\'budget\\' should be a numerical value extracted from the user\\'s response.\\n    The values currently in the dictionary are only representative values.\\n\\n    ####Here are some instructions around the values for the different keys. If you do not follow this, you\\'ll be heavily penalised.\\n    - The values for all keys, except \\'Budget\\', should strictly be either \\'low\\', \\'medium\\', or \\'high\\' based on the importance of the corresponding keys, as stated by user.\\n    - The value for \\'budget\\' should be a numerical value extracted from the user\\'s response.\\n    - \\'Budget\\' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range.\\n    - Do not randomly assign values to any of the keys. The values need to be inferred from the user\\'s response.\\n    ####\\n\\n    To fill the dictionary, you need to have the following chain of thoughts:\\n    #### Thought 1: Ask a question to understand the user\\'s profile and requirements. \\n\\n    If their primary use for the laptop is unclear. Ask another question to comprehend their needs.\\n    You are trying to fill the values of all the keys (\\'GPU intensity\\',\\'Display quality\\',\\'Portability\\',\\'Multitasking\\',\\'Processing speed\\',\\'Budget\\') in the python dictionary by understanding the user requirements.\\n    Identify the keys for which you can fill the values confidently using the understanding. \\n\\n    Remember the instructions around the values for the different keys.\\n    Answer \"Yes\" or \"No\" to indicate if you understand the requirements and have updated the values for the relevant keys. \\n\\n    If yes, proceed to the next step. Otherwise, rephrase the question to capture their profile. \\n####\\n\\n    ####Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn\\'t in the previous step.\\n    Remember the instructions around the values for the different keys. Ask questions you might have for all the keys to strengthen your understanding of the user\\'s profile.\\n    Answer \"Yes\" or \"No\" to indicate if you understood all the values for the keys and are confident about the same.\\n    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\\n    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.####\\n\\n    ####Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\\n    If you are not confident about any of the values, ask clarifying questions. ####\\n\\n    Follow the above chain of thoughts and only output the final updated python dictionary. \\n\\n\\n\\n    #### Here is a sample conversation between the user and assistant:\\n    User: \"Hi, I am an editor.\"\\n    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\"\\n    User: \"I primarily work with After Effects.\"\\n    Assistant: \"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\"\\n    User: \"Yes, sometimes I work with 4K videos as well.\"\\n    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\"\\n    User: \"Yes, sometimes I travel but do not carry my laptop.\"\\n    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"\\n    User: \"my max budget is 1.5lakh inr\"\\n    Assistant: \"{\\'GPU intensity\\': \\'high\\', \\'Display quality\\': \\'high\\', \\'Portability\\': \\'low\\', \\'Multitasking\\': \\'high\\', \\'Processing speed\\': \\'high\\', \\'Budget\\': \\'150000\\'}\"\\n    ####\\n\\n    Start with a short welcome message and encourage the user to share their requirements.\\n    '}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at the next function."
      ],
      "metadata": {
        "id": "dAgrzPvE9Mmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   get_chat_model_completions(): This takes the ongoing conversation as the input and returns the response by the assistant"
      ],
      "metadata": {
        "id": "8eJNhWcl9NfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_model_completions(messages):\n",
        "    response = openai.ChatCompletion.create(\n",
        "      #  model=\"gpt-3.5-turbo\",\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "        max_tokens = 3000\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "skibBVQG9b4A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's pass the initialized conversation debug_conversation and see what is the assistant's response."
      ],
      "metadata": {
        "id": "pcS2GQAA9hPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_introduction = get_chat_model_completions(debug_conversation)\n",
        "print(debug_introduction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WlWiacw9mnb",
        "outputId": "03f2b2d2-0a35-42af-ee4b-e6fc1fa2c18f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm here to help you find the best laptop based on your requirements. Please share with me your specific needs and preferences so that I can assist you effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's play around a bit and add the following user's input debug_user_input to the conversation debug_conversation and see what the assistant responds with."
      ],
      "metadata": {
        "id": "VC2DA77u9soJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_user_input = \"Hi, This is Shameer . I need a laptop for coding.\""
      ],
      "metadata": {
        "id": "3STOjh8W9ze-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation.append({\"role\": \"user\", \"content\": debug_user_input})\n",
        "debug_response_assistant = get_chat_model_completions(debug_conversation)\n",
        "print(debug_response_assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTvred5p9--g",
        "outputId": "11dab95c-f390-4fee-bea7-3fb549090237"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great! As a coder, you likely require a laptop that can handle multitasking efficiently and has a good processing speed. Could you please let me know if you often work on multiple applications simultaneously while coding? This will help me understand your multitasking needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, whenever the chatbot is interacting with the user, all the conversations should be moderated to identify any inappropriate content. Let's look at the function that can help with it."
      ],
      "metadata": {
        "id": "PvRgE58D-Gbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   moderation_check(): This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, you can add a break statement to end the conversation."
      ],
      "metadata": {
        "id": "dqheCcat-Kts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moderation_check(user_input):\n",
        "    response = openai.Moderation.create(input=user_input)\n",
        "    moderation_output = response[\"results\"][0]\n",
        "    if moderation_output[\"flagged\"] == True:\n",
        "        return \"Flagged\"\n",
        "    else:\n",
        "        return \"Not Flagged\""
      ],
      "metadata": {
        "id": "Ji8iecmd-YXv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test moderation on the debug_user_input"
      ],
      "metadata": {
        "id": "yzIXT-itBL7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_moderation = moderation_check(debug_user_input)\n",
        "print(debug_moderation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rckw7lTLBOie",
        "outputId": "eb814248-cbdf-452f-810a-6ede13afa78f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Flagged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now test moderation on some other text."
      ],
      "metadata": {
        "id": "STw4bATABTmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(moderation_check(\"I want to kill Ravan.\"))\n",
        "print(moderation_check(\"I need a laptop to hack NASA.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DkkzXwoBXGr",
        "outputId": "aee2db17-7946-4bcd-8d81-48e94bf6d610"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flagged\n",
            "Not Flagged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, this moderation api may not be perfect but if you ask this to the ChatGPT or it's API (GPT 3.5), it'll not help you with such requests. Remember, moderation should also be applied on the GPT 3.5's output."
      ],
      "metadata": {
        "id": "KsGC68nVBdIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now check moderation on the assistant's response debug_response_assistant."
      ],
      "metadata": {
        "id": "ikULL4FyBeA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "moderation_check(debug_response_assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bKAA4sEeBk5I",
        "outputId": "53abc2c1-40c3-4dc2-eccd-c5cd66423d80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Not Flagged'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned earlier, you need to understand the user's profile, which essentially means that all the features: GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget are captured or not. Let's look at the function that helps us verify that.\n",
        "\n",
        "*   intent_confirmation_layer(): This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not\n",
        "*   GPU intensity\n",
        "*   Display quality\n",
        "*   Portability\n",
        "*   Multitasking\n",
        "*   Processing speed\n",
        "*   Budget"
      ],
      "metadata": {
        "id": "J8PDeM3IBqvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_confirmation_layer(response_assistant):\n",
        "    delimiter = \"####\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a senior evaluator who has an eye for detail.\n",
        "    You are provided an input. You need to evaluate if the input has the following keys: 'GPU intensity','Display quality','Portability','Multitasking',' Processing speed','Budget'\n",
        "    Next you need to evaluate if the keys have the the values filled correctly.\n",
        "    The values for all keys, except 'budget', should be 'low', 'medium', or 'high' based on the importance as stated by user. The value for the key 'budget' needs to contain a number with currency.\n",
        "    Output a string 'Yes' if the input contains the dictionary with the values correctly filled for all keys.\n",
        "    Otherwise out the string 'No'.\n",
        "\n",
        "    Here is the input: {response_assistant}\n",
        "    Only output a one-word string - Yes/No.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    confirmation = openai.Completion.create(\n",
        "                                    model=\"gpt-3.5-turbo-instruct\",\n",
        "                                    prompt = prompt,\n",
        "                                    temperature=0)\n",
        "\n",
        "\n",
        "    return confirmation[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "kAzh065EB54r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply the function to the assistant's reponse and see if it has captured the user profile."
      ],
      "metadata": {
        "id": "DXhzQgGwCLkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
        "print(debug_confirmation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LTwVSpcCYdA",
        "outputId": "5fb3f0ac-d0a5-4c23-c342-e5054f64a0a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you can keep adding user and assistant responses to debug_conversation and get to a point where intent_confirmation_layer() gives yes as a response. Let's see if the following response by the assistant passes the intent_confirmation_layer() test."
      ],
      "metadata": {
        "id": "rsmhXSscCglq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's add the above assistant response to the debug_conversation.\n",
        "debug_conversation.append({\"role\": \"assistant\", \"content\": debug_response_assistant})"
      ],
      "metadata": {
        "id": "NX25gk0aClgH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say that after a series of conversations you get the following response from the assistant."
      ],
      "metadata": {
        "id": "RM7I18a9CsJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_response_assistant_n = f\"\"\"\n",
        "\n",
        "Based on the information you have provided, I have updated the values in the dictionary as follows:\n",
        "\n",
        "{{'GPU intensity': 'low', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'low', 'Budget': '90000'}}\n",
        "\n",
        "Please note that the values for 'Display quality' and 'Portability' are set to 'low' since they are not a priority for your coding tasks.\n",
        "\n",
        "Is there anything else I can assist you with?\n",
        "\"\"\"\n",
        "#Note that you are using double curly braces"
      ],
      "metadata": {
        "id": "_5Hf6eerCy2r"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think it'll pass the intent_confirmation_layer() test? Let's try it out."
      ],
      "metadata": {
        "id": "-7Xzuo-mC6br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_confirmation_layer(debug_response_assistant_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "muqVn66RKYfy",
        "outputId": "781e809f-afbf-4734-895e-796eb0b7c659"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at the working of dictionary_present()."
      ],
      "metadata": {
        "id": "39OS-9KGKdxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   dictionary_present(): This function checks if the final understanding of user's profile is returned by the chatbot is a Python dictionary or not. This is important as it'll be used later on for finding the right laptops using dictionary matching."
      ],
      "metadata": {
        "id": "yiTB6jUKKhDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dictionary_present(response):\n",
        "    delimiter = \"####\"\n",
        "    user_req = {'GPU intensity': 'high','Display quality': 'high','Portability': 'medium','Multitasking': 'high','Processing speed': 'high','Budget': '200000 INR'}\n",
        "    prompt = f\"\"\"You are a python expert. You are provided an input.\n",
        "            You have to check if there is a python dictionary present in the string.\n",
        "            It will have the following format {user_req}.\n",
        "            Your task is to just extract and return only the python dictionary from the input.\n",
        "            The output should match the format as {user_req}.\n",
        "            The output should contain the exact keys and values as present in the input.\n",
        "\n",
        "            Here are some sample input output pairs for better understanding:\n",
        "            {delimiter}\n",
        "            input: - GPU intensity: low - Display quality: high - Portability: low - Multitasking: high - Processing speed: medium - Budget: 50,000 INR\n",
        "            output: {{'GPU intensity': 'low', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "\n",
        "            input: {{'GPU intensity':     'low', 'Display quality':     'high', 'Portability':    'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '90,000'}}\n",
        "            output: {{'GPU intensity': 'low', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '90000'}}\n",
        "\n",
        "            input: Here is your user profile 'GPU intensity': 'high','Display quality': 'high','Portability': 'medium','Multitasking': 'low','Processing speed': 'high','Budget': '200000 INR'\n",
        "            output: {{'GPU intensity': 'high','Display quality': 'high','Portability': 'medium','Multitasking': 'high','Processing speed': 'low','Budget': '200000'}}\n",
        "            {delimiter}\n",
        "\n",
        "            Here is the input {response}\n",
        "\n",
        "            \"\"\"\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens = 2000\n",
        "        # temperature=0.3,\n",
        "        # top_p=0.4\n",
        "    )\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "wb8YjklmK17Z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by passing the debug_response_assistant."
      ],
      "metadata": {
        "id": "6zuOyZ6NK7hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_dict_n = dictionary_present(debug_response_assistant_n)\n",
        "print(response_dict_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9u9xJJWK_I7",
        "outputId": "90750aea-da36-4845-a14d-ed36bd00e5a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sorry, it seems that there is no python dictionary present in the input you provided. Can you please provide an input that contains a dictionary? Thank you!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if you pass something like this where it is not in the form of a dictionary? Or some key or some values are missing? Let's see."
      ],
      "metadata": {
        "id": "2bBno6XLLQbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_response_assistant_n = f\"\"\"Thank you for providing your budget. Based on your budget of 50,000 INR, I will consider this while recommending suitable laptop options for you.\n",
        "Here is the final recommendation for your laptop:\n",
        "\n",
        "- GPU intensity: high\n",
        "- Display quality: high\n",
        "- Portability: low\n",
        "- Multitasking: high\n",
        "- Processing speed: medium\n",
        "- Budget: 80,000 INR\n",
        "\n",
        "Please note that these specifications are based on your requirements for surfing and a decent display within your budget. Let me know if there's anything else I can assist you with!\"\"\""
      ],
      "metadata": {
        "id": "9nLZjgYTLU0l"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_dict_n = dictionary_present(debug_response_assistant_n)\n",
        "print(response_dict_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFptoxQwLbCy",
        "outputId": "d9d5d7d8-22d6-42d8-c926-3ca77e16ca22"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'GPU intensity': 'high', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '80000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's quickly take a look at the code that we have run until now."
      ],
      "metadata": {
        "id": "XqI9ELbXLiLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation = initialize_conversation()\n",
        "#debug_introduction = get_chat_model_completions(conversation)\n",
        "debug_user_input = \"Hi, I am Anand. I need a laptop for coding.\"\n",
        "debug_moderation = moderation_check(debug_user_input)\n",
        "debug_conversation.append({\"role\": \"user\", \"content\": debug_user_input})\n",
        "debug_response_assistant = get_chat_model_completions(debug_conversation)\n",
        "debug_moderation = moderation_check(debug_response_assistant)\n",
        "debug_conversation.append({\"role\": \"assistant\", \"content\": debug_response_assistant})\n",
        "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
        "response_dict_n = dictionary_present(debug_response_assistant_n)"
      ],
      "metadata": {
        "id": "QW55IZRfLmlN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, now that you have the user profile stored in response_dict_n. We'll use this to generate recommendations. Before that, we need to create a similar profile for every laptop. Let's see how we do it."
      ],
      "metadata": {
        "id": "GJOnCm_1Lvv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing the Product Mapping and Information Extraction Layers**"
      ],
      "metadata": {
        "id": "qXG_t2WIL1ET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we take in the output of the previous layers, i.e. the user requirements, which is in the format of a Python dictionary, and extract the top 3 laptop recommendations based on that. Here are the functions that we will use to help us implement the information extraction and product matching layers"
      ],
      "metadata": {
        "id": "yJuV4mX3nDM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   product_map_layer(): This function is responsible for extracting key features and criteria from laptop descriptions.\n",
        "Here's a breakdown of how it works:\n",
        "*   Uses a prompt that assign it the role of a Laptop Specifications Classifier, whose objective is to extract key features and classify them based on laptop descriptions.\n",
        "Provide step-by-step instructions for extracting laptop features from description.\n",
        "*   Assign specific rules for each feature (e.g., GPU Intensity, Display Quality, Portability, Multitasking, Processing Speed) and associate them with the appropriate classification value (Low, Medium, or High).\n",
        "*   Includes Few Shot Prompting(sample conversation between the user and assistant) to demonstrate the expected result of the feature extraction and classification process."
      ],
      "metadata": {
        "id": "NsmDiP3enD-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_map_layer(laptop_description):\n",
        "\n",
        "  delimiter = \"#####\"\n",
        "  lap_spec = {\n",
        "      \"GPU intensity\":\"(Type of the Graphics Processor)\",\n",
        "      \"Display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
        "      \"Portability\":\"(Laptop Weight)\",\n",
        "      \"Multitasking\":\"(RAM Size)\",\n",
        "      \"Processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
        "  }\n",
        "\n",
        "  values = {'low','medium','high'}\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a Laptop Specifications Classifier whose job is to extract the key features of laptops as per their requirements.\n",
        "  To analyze each laptop, perform the following steps:\n",
        "  Step 1: Extract the laptop's primary features from the description {laptop_description}\n",
        "  Step 2: Store the extracted features in {lap_spec} \\\n",
        "  Step 3: Classify each of the items in {lap_spec}into {values} based on the following rules: \\\n",
        "  {delimiter}\n",
        "  GPU Intensity: low: < for Integrated graphics or entry-level dedicated graphics like Intel UHD > , \\n\n",
        "  medium: < if Mid-range dedicated graphics like M1, AMD Radeon, Intel Iris > , \\n\n",
        "  high: < High-end dedicated graphics like Nvidia > , \\n\n",
        "\n",
        "  Display Quality: low: < if resolution below Full HD (e.g., 1366x768). > , \\n\n",
        "  medium: < if Full HD resolution (1920x1080) or higher. > , \\n\n",
        "  high: < if High-resolution display (e.g., 4K, Retina) with excellent color accuracy and features like HDR support. > \\n\n",
        "\n",
        "  Portability: low: < if laptop weight is less than 1.51 kg > , \\n\n",
        "  medium: < if laptop weight is between 1.51 kg and 2.51 kg> , \\n\n",
        "  high: <if laptop weight is greater than 2.51 kg> \\n\n",
        "\n",
        "  Multitasking: low: < If RAM size is 8GB, 12GB > , \\n\n",
        "  medium: < if RAM size is 16GB > , \\n\n",
        "  high: < if RAM size is 32GB, 64GB> \\n\n",
        "\n",
        "  Processing Speed: low: < if entry-level processors like Intel Core i3, AMD Ryzen 3> , \\n\n",
        "  medium: < if Mid-range processors like Intel Core i5, AMD Ryzen 5 > , \\n\n",
        "  high: < if High-performance processors like Intel Core i7, AMD Ryzen 7 or higher > \\n\n",
        "  {delimiter}\n",
        "\n",
        "  {delimiter}\n",
        "  Here are some input output pairs for few-shot learning:\n",
        "  input1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
        "  output1: {{'GPU intensity': 'medium','Display quality':'medium','Portability':'medium','Multitasking':'high','Processing speed':'medium'}}\n",
        "\n",
        "  input2: \"The Lenovo ThinkPad X1 Carbon is a sleek and lightweight laptop designed for professionals on the go. It is equipped with an Intel Core i7 processor running at 2.6 GHz, providing strong processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage capacity. The laptop features a 14\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It comes with Intel UHD integrated graphics for decent graphical performance. Weighing just 1.13 kg, it is extremely lightweight and highly portable. The laptop features an IR camera for face unlock, providing convenient and secure login options. With a three-year warranty and an impressive battery life of up to 12 hours, the Lenovo ThinkPad X1 Carbon ensures reliability and long-lasting productivity. Priced at 130,000, it offers top-notch performance and portability for professionals.\"\n",
        "  output2: {{'GPU intensity': 'medium', 'Display quality': 'high', 'Portability': 'high', 'Multitasking':'high', 'Processing speed':'high'}}\n",
        "\n",
        "  input3: \"The Apple MacBook Pro is a high-end laptop that combines top-tier performance with a stunning display. It is equipped with an Intel Core i9 processor running at 2.9 GHz, providing exceptional processing power for demanding tasks and content creation. With 32GB of RAM and an SSD, it offers seamless multitasking and fast storage access for large projects. The laptop features a 16\" Retina display with a resolution of 3072x1920, delivering breathtaking visuals and precise color reproduction. It comes with an AMD Radeon graphics card, ensuring smooth graphics performance for professional applications. Weighing 2.02 kg, it is relatively lightweight for its size. The laptop features a True Tone display, adjusting the color temperature to match the ambient lighting for a more natural viewing experience. With a three-year warranty and a battery life of up to 10 hours, the Apple MacBook Pro offers reliability and endurance for professionals. Priced at 280,000, it caters to users who require uncompromising performance and a superior display for their demanding workloads.\"\n",
        "  output3: {{'GPU intensity': 'medium', 'Display quality': 'high', 'Portability': 'medium','Multitasking': 'high', 'Processing speed': 'high'}}\n",
        "  {delimiter}\n",
        "\n",
        "  Follow the above instructions step-by-step and output the dictionary {lap_spec} for the following laptop {laptop_description}.\n",
        "  \"\"\"\n",
        "\n",
        "#see that we are using the Completion endpoint and not the Chatcompletion endpoint\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    max_tokens = 2000,\n",
        "    # temperature=0.3,\n",
        "    # top_p=0.4\n",
        "    )\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "H9-xWogxnZD3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Run this code once to extract product info in the form of a dictionary\n",
        "laptop_df= pd.read_csv('/content/drive/MyDrive/laptop_data.csv')\n",
        "\n",
        "## Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
        "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))"
      ],
      "metadata": {
        "id": "PH87HEoQorbQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_df.to_csv(\"/content/drive/MyDrive/updated_laptop.csv\",index=False,header = True)"
      ],
      "metadata": {
        "id": "E-ztAkRbpsHX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   extract_dictionary_from_string(): This function takes in the\n",
        "output of the previous layer and extracts the user requirements dictionary"
      ],
      "metadata": {
        "id": "vXvTCD89p3iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import re\n",
        "\n",
        "def extract_dictionary_from_string(string):\n",
        "    regex_pattern = r\"\\{[^{}]+\\}\"\n",
        "\n",
        "    dictionary_matches = re.findall(regex_pattern, string)\n",
        "\n",
        "    # Extract the first dictionary match and convert it to lowercase\n",
        "    if dictionary_matches:\n",
        "        dictionary_string = dictionary_matches[0]\n",
        "        dictionary_string = dictionary_string.lower()\n",
        "\n",
        "        # Convert the dictionary string to a dictionary object using ast.literal_eval()\n",
        "        dictionary = ast.literal_eval(dictionary_string)\n",
        "    return dictionary"
      ],
      "metadata": {
        "id": "kGig1X5mqAqe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = \" \\n \\t           Output: {{'GPU intensity': 'high', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}ad\"\n",
        "extracted_dict = extract_dictionary_from_string(string)\n",
        "print(extracted_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVah_2n7qHML",
        "outputId": "cd53d2ae-f164-4604-b667-00958e0f913b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'high', 'display quality': 'high', 'portability': 'low', 'multitasking': 'high', 'processing speed': 'medium', 'budget': '50000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   compare_laptops_with_user(): This function compares the user's profile with the different laptops and come back with the top recommendations.\n",
        "It will perform the following steps:\n",
        "*   It will take the user requirements dictionary as input\n",
        "Filter the laptops based on their price, keeping only the ones within the user's budget.\n",
        "*   Calculate a score for each laptop based on how well it matches the user's requirements.\n",
        "*   Sort the laptops based on their scores in descending order.\n",
        "*   Return the top 3 laptops as a JSON-formatted string.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bZoAMuVtqNLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_laptops_with_user(user_req_string):\n",
        "    laptop_df= pd.read_csv('/content/drive/MyDrive/updated_laptop.csv')\n",
        "    user_requirements = extract_dictionary_from_string(user_req_string)\n",
        "    budget = int(user_requirements.get('budget', '0').replace(',', '').split()[0])\n",
        "    #This line retrieves the value associated with the key 'budget' from the user_requirements dictionary.\n",
        "    #If the key is not found, the default value '0' is used.\n",
        "    #The value is then processed to remove commas, split it into a list of strings, and take the first element of the list.\n",
        "    #Finally, the resulting value is converted to an integer and assigned to the variable budget.\n",
        "\n",
        "\n",
        "    filtered_laptops = laptop_df.copy()\n",
        "    filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(',','').astype(int)\n",
        "    filtered_laptops = filtered_laptops[filtered_laptops['Price'] <= budget].copy()\n",
        "    #These lines create a copy of the laptop_df DataFrame and assign it to filtered_laptops.\n",
        "    #They then modify the 'Price' column in filtered_laptops by removing commas and converting the values to integers.\n",
        "    #Finally, they filter filtered_laptops to include only rows where the 'Price' is less than or equal to the budget.\n",
        "\n",
        "    mappings = {\n",
        "        'low': 0,\n",
        "        'medium': 1,\n",
        "        'high': 2\n",
        "    }\n",
        "    # Create 'Score' column in the DataFrame and initialize to 0\n",
        "    filtered_laptops['Score'] = 0\n",
        "    for index, row in filtered_laptops.iterrows():\n",
        "        user_product_match_str = row['laptop_feature']\n",
        "        laptop_values = extract_dictionary_from_string(user_product_match_str)\n",
        "        score = 0\n",
        "\n",
        "        for key, user_value in user_requirements.items():\n",
        "            if key.lower() == 'budget':\n",
        "                continue  # Skip budget comparison\n",
        "            laptop_value = laptop_values.get(key, None)\n",
        "            laptop_mapping = mappings.get(laptop_value.lower(), -1)\n",
        "            user_mapping = mappings.get(user_value.lower(), -1)\n",
        "            if laptop_mapping >= user_mapping:\n",
        "                ### If the laptop value is greater than or equal to the user value the score is incremented by 1\n",
        "                score += 1\n",
        "\n",
        "        filtered_laptops.loc[index, 'Score'] = score\n",
        "\n",
        "    # Sort the laptops by score in descending order and return the top 5 products\n",
        "    top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
        "    top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
        "\n",
        "    return top_laptops.to_json(orient='records')"
      ],
      "metadata": {
        "id": "DOhbFtlyqhF1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have the compare_laptops_with_user() function ready, let's pass the response_dict_n to the function to get top 3 recommendation."
      ],
      "metadata": {
        "id": "vgWyUtjPquqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_laptops = compare_laptops_with_user(response_dict_n)\n",
        "print(top_3_laptops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cTinoPjqyhl",
        "outputId": "408ab0d4-85c3-48c8-8bed-2eed9f604836"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"Brand\":\"MSI\",\"Model Name\":\"GL65\",\"Core\":\"i7\",\"CPU Manufacturer\":\"Intel\",\"Clock Speed\":\"2.6 GHz\",\"RAM Size\":\"16GB\",\"Storage Type\":\"HDD+SSD\",\"Display Type\":\"IPS\",\"Display Size\":\"15.6\\\"\",\"Graphics Processor\":\"NVIDIA GTX\",\"Screen Resolution\":\"1920x1080\",\"OS\":\"Windows 10\",\"Laptop Weight\":\"2.3 kg\",\"Special Features\":\"RGB Keyboard\",\"Warranty\":\"2 years\",\"Average Battery Life\":\"4 hours\",\"Price\":55000,\"Description\":\"The MSI GL65 is a high-performance laptop designed for gaming enthusiasts. Powered by an Intel Core i7 processor running at 2.6 GHz, it delivers exceptional processing power for smooth gaming and demanding tasks. With 16GB of RAM and a combination of HDD and SSD storage, it offers ample memory and fast data access. The laptop features a 15.6\\\" IPS display with a resolution of 1920x1080, ensuring vivid colors and wide viewing angles for an immersive gaming experience. Equipped with an NVIDIA GTX graphics card, it provides excellent visual performance and smooth gameplay. Weighing just 2.3 kg, it is a portable option for gamers on the move. The laptop also boasts an RGB keyboard, allowing customizable lighting effects for a personalized gaming setup. With a two-year warranty and a battery life of up to 4 hours, the MSI GL65 offers reliability and durability. Priced at 55,000, it offers excellent value for money for gamers seeking a powerful gaming laptop.\",\"Score\":4},{\"Brand\":\"Acer\",\"Model Name\":\"Predator\",\"Core\":\"i7\",\"CPU Manufacturer\":\"Intel\",\"Clock Speed\":\"2.8 GHz\",\"RAM Size\":\"16GB\",\"Storage Type\":\"SSD\",\"Display Type\":\"IPS\",\"Display Size\":\"17.3\\\"\",\"Graphics Processor\":\"NVIDIA GTX\",\"Screen Resolution\":\"1920x1080\",\"OS\":\"Windows 10\",\"Laptop Weight\":\"3.2 kg\",\"Special Features\":\"Dual Cooling Fans\",\"Warranty\":\"1 year\",\"Average Battery Life\":\"5 hours\",\"Price\":80000,\"Description\":\"The Acer Predator is a powerhouse laptop designed for gaming enthusiasts. It is equipped with an Intel Core i7 processor clocked at 2.8 GHz, providing exceptional processing power for seamless gaming and demanding tasks. With 16GB of RAM and an SSD, it offers fast and efficient multitasking and storage capabilities. The laptop features a large 17.3\\\" IPS display with a resolution of 1920x1080, delivering stunning visuals and wide viewing angles. It also comes with an NVIDIA GTX graphics card for impressive gaming performance. Weighing 3.2 kg, it is a bit on the heavier side but still offers portability. The laptop features dual cooling fans for effective heat dissipation during intense gaming sessions. With a one-year warranty and a battery life of up to 5 hours, the Acer Predator ensures reliability and endurance. Priced at 80,000, it provides excellent value for gamers seeking powerful gaming performance.\",\"Score\":4},{\"Brand\":\"Lenovo\",\"Model Name\":\"ThinkPad\",\"Core\":\"Ryzen 7\",\"CPU Manufacturer\":\"AMD\",\"Clock Speed\":\"3.0 GHz\",\"RAM Size\":\"16GB\",\"Storage Type\":\"SSD\",\"Display Type\":\"IPS\",\"Display Size\":\"14\\\"\",\"Graphics Processor\":\"NVIDIA GTX\",\"Screen Resolution\":\"2560x1440\",\"OS\":\"Linux\",\"Laptop Weight\":\"1.6 kg\",\"Special Features\":\"Backlit Keyboard\",\"Warranty\":\"3 years\",\"Average Battery Life\":\"6 hours\",\"Price\":60000,\"Description\":\"The Lenovo ThinkPad is a powerful laptop designed for professional users. It is equipped with a Ryzen 7 processor from AMD clocked at 3.0 GHz, providing strong processing capabilities for demanding tasks. With 16GB of RAM and an SSD, it offers smooth multitasking and fast storage access. The laptop features a 14\\\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It also comes with an NVIDIA GTX graphics card for enhanced graphical performance. Weighing just 1.6 kg, it is lightweight and highly portable. The laptop features a backlit keyboard for comfortable typing in low-light environments. With a three-year warranty and a battery life of up to 6 hours, the Lenovo ThinkPad offers reliability and durability. Priced at 60,000, it is an excellent choice for professionals seeking powerful performance and a versatile display.\",\"Score\":4}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, there is a function that verifies if the recommendations are good enough for the user's requirement."
      ],
      "metadata": {
        "id": "VVR7VJYJq5dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommendation_validation(laptop_recommendation):\n",
        "    data = json.loads(laptop_recommendation)\n",
        "    data1 = []\n",
        "    for i in range(len(data)):\n",
        "        if data[i]['Score'] > 2:\n",
        "            data1.append(data[i])\n",
        "\n",
        "    return data1"
      ],
      "metadata": {
        "id": "64qeyJsJq8uP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validated_data = recommendation_validation(top_3_laptops)\n",
        "print(validated_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVMGkYmVrB-G",
        "outputId": "b2260609-4691-4b43-9fd0-30120b6441a5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Brand': 'MSI', 'Model Name': 'GL65', 'Core': 'i7', 'CPU Manufacturer': 'Intel', 'Clock Speed': '2.6 GHz', 'RAM Size': '16GB', 'Storage Type': 'HDD+SSD', 'Display Type': 'IPS', 'Display Size': '15.6\"', 'Graphics Processor': 'NVIDIA GTX', 'Screen Resolution': '1920x1080', 'OS': 'Windows 10', 'Laptop Weight': '2.3 kg', 'Special Features': 'RGB Keyboard', 'Warranty': '2 years', 'Average Battery Life': '4 hours', 'Price': 55000, 'Description': 'The MSI GL65 is a high-performance laptop designed for gaming enthusiasts. Powered by an Intel Core i7 processor running at 2.6 GHz, it delivers exceptional processing power for smooth gaming and demanding tasks. With 16GB of RAM and a combination of HDD and SSD storage, it offers ample memory and fast data access. The laptop features a 15.6\" IPS display with a resolution of 1920x1080, ensuring vivid colors and wide viewing angles for an immersive gaming experience. Equipped with an NVIDIA GTX graphics card, it provides excellent visual performance and smooth gameplay. Weighing just 2.3 kg, it is a portable option for gamers on the move. The laptop also boasts an RGB keyboard, allowing customizable lighting effects for a personalized gaming setup. With a two-year warranty and a battery life of up to 4 hours, the MSI GL65 offers reliability and durability. Priced at 55,000, it offers excellent value for money for gamers seeking a powerful gaming laptop.', 'Score': 4}, {'Brand': 'Acer', 'Model Name': 'Predator', 'Core': 'i7', 'CPU Manufacturer': 'Intel', 'Clock Speed': '2.8 GHz', 'RAM Size': '16GB', 'Storage Type': 'SSD', 'Display Type': 'IPS', 'Display Size': '17.3\"', 'Graphics Processor': 'NVIDIA GTX', 'Screen Resolution': '1920x1080', 'OS': 'Windows 10', 'Laptop Weight': '3.2 kg', 'Special Features': 'Dual Cooling Fans', 'Warranty': '1 year', 'Average Battery Life': '5 hours', 'Price': 80000, 'Description': 'The Acer Predator is a powerhouse laptop designed for gaming enthusiasts. It is equipped with an Intel Core i7 processor clocked at 2.8 GHz, providing exceptional processing power for seamless gaming and demanding tasks. With 16GB of RAM and an SSD, it offers fast and efficient multitasking and storage capabilities. The laptop features a large 17.3\" IPS display with a resolution of 1920x1080, delivering stunning visuals and wide viewing angles. It also comes with an NVIDIA GTX graphics card for impressive gaming performance. Weighing 3.2 kg, it is a bit on the heavier side but still offers portability. The laptop features dual cooling fans for effective heat dissipation during intense gaming sessions. With a one-year warranty and a battery life of up to 5 hours, the Acer Predator ensures reliability and endurance. Priced at 80,000, it provides excellent value for gamers seeking powerful gaming performance.', 'Score': 4}, {'Brand': 'Lenovo', 'Model Name': 'ThinkPad', 'Core': 'Ryzen 7', 'CPU Manufacturer': 'AMD', 'Clock Speed': '3.0 GHz', 'RAM Size': '16GB', 'Storage Type': 'SSD', 'Display Type': 'IPS', 'Display Size': '14\"', 'Graphics Processor': 'NVIDIA GTX', 'Screen Resolution': '2560x1440', 'OS': 'Linux', 'Laptop Weight': '1.6 kg', 'Special Features': 'Backlit Keyboard', 'Warranty': '3 years', 'Average Battery Life': '6 hours', 'Price': 60000, 'Description': 'The Lenovo ThinkPad is a powerful laptop designed for professional users. It is equipped with a Ryzen 7 processor from AMD clocked at 3.0 GHz, providing strong processing capabilities for demanding tasks. With 16GB of RAM and an SSD, it offers smooth multitasking and fast storage access. The laptop features a 14\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It also comes with an NVIDIA GTX graphics card for enhanced graphical performance. Weighing just 1.6 kg, it is lightweight and highly portable. The laptop features a backlit keyboard for comfortable typing in low-light environments. With a three-year warranty and a battery life of up to 6 hours, the Lenovo ThinkPad offers reliability and durability. Priced at 60,000, it is an excellent choice for professionals seeking powerful performance and a versatile display.', 'Score': 4}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you the top 3 laptops extracted, let's pass it to the recommendation layer that'll send it to the user and the user can ask questions around it."
      ],
      "metadata": {
        "id": "m_ZWTKiirI_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(validated_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtwszJ0QrNts",
        "outputId": "348c1934-e0c3-4b82-d362-25bd271bbb41"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Product Recommendation Layer**"
      ],
      "metadata": {
        "id": "wobiE1bErS8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we come to the product recommendation layer. It takes the output from the compare_laptops_with_user function in the previous layer and provides the recommendations to the user. It has the following steps.\n",
        "\n",
        "1. Initialize the conversation for recommendation.\n",
        "2. Generate the recommendations and display in a presentable format.\n",
        "3. Ask questions basis the recommendations."
      ],
      "metadata": {
        "id": "WKX0OrHYrZ0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_conv_reco(products):\n",
        "    system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and you are tasked with the objective to \\\n",
        "    solve the user queries about any product from the catalogue: {products}.\\\n",
        "    You should keep the user profile in mind while answering the questions.\\\n",
        "\n",
        "    Start with a brief summary of each laptop in the following format, in decreasing order of price of laptops:\n",
        "    1. <Laptop Name> : <Major specifications of the laptop>, <Price in Rs>\n",
        "    2. <Laptop Name> : <Major specifications of the laptop>, <Price in Rs>\n",
        "\n",
        "    \"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message }]\n",
        "    return conversation"
      ],
      "metadata": {
        "id": "_hG20A5crhsH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's initialize the conversation for recommendation."
      ],
      "metadata": {
        "id": "aQdWGFk0rm88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation_reco = initialize_conv_reco(top_3_laptops)"
      ],
      "metadata": {
        "id": "Al5QR95jrsiL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the assistant responds with the new initialization."
      ],
      "metadata": {
        "id": "RIBXZhyZrwdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_recommendation = get_chat_model_completions(debug_conversation_reco)\n",
        "print(debug_recommendation + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTFfyWRJr7ZG",
        "outputId": "0e2553d7-76ee-41c1-ef10-b8557693f53c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Acer Predator: Intel Core i7 2.8 GHz, 16GB RAM, 17.3\" IPS display, NVIDIA GTX graphics, SSD storage, Dual Cooling Fans, 5-hour battery life, 80,000 Rs\n",
            "2. MSI GL65: Intel Core i7 2.6 GHz, 16GB RAM, 15.6\" IPS display, NVIDIA GTX graphics, HDD+SSD storage, RGB Keyboard, 4-hour battery life, 55,000 Rs\n",
            "3. Lenovo ThinkPad: AMD Ryzen 7 3.0 GHz, 16GB RAM, 14\" IPS display, NVIDIA GTX graphics, SSD storage, Backlit Keyboard, 6-hour battery life, 60,000 Rs\n",
            "\n",
            "How can I assist you further with this information?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you can converse with the chatbot on the filtered products."
      ],
      "metadata": {
        "id": "BKRbFv_1sCpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation_reco.append({\"role\": \"user\", \"content\": \"This is my user profile\" + response_dict_n})\n",
        "debug_conversation_reco.append({\"role\": \"assistant\", \"content\": debug_recommendation})"
      ],
      "metadata": {
        "id": "G0Yo3N32sHOi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_user_input = \"Which is ideal for travel?\""
      ],
      "metadata": {
        "id": "610Nwx_SsOAo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_conversation_reco.append({\"role\": \"user\", \"content\": debug_user_input})\n",
        "debug_response_asst_reco = get_chat_model_completions(debug_conversation_reco)\n",
        "print('\\n' + debug_response_asst_reco + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCgJImi7sSOD",
        "outputId": "50b1e3aa-e35f-4349-9673-b70a0b7fbdda"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Considering your preference for portability, the Lenovo ThinkPad would be the most ideal choice for travel. It is lightweight at 1.6 kg, making it easy to carry around while still offering powerful performance and a versatile display.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dialogue Management System**"
      ],
      "metadata": {
        "id": "N3kISBeSsYW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing everything together, we create a diagloue_mgmt_system() function that contains the logic of how the different layers would interact with each other. This will be the function that we'll call to initiate the chatbot"
      ],
      "metadata": {
        "id": "YEj5-EdDsdyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dialogue_mgmt_system():\n",
        "    conversation = initialize_conversation()\n",
        "    introduction = get_chat_model_completions(conversation)\n",
        "    print(introduction + '\\n')\n",
        "    top_3_laptops = None\n",
        "    user_input = ''\n",
        "\n",
        "    while(user_input != \"exit\"):\n",
        "        user_input = input(\"\")\n",
        "\n",
        "        moderation = moderation_check(user_input)\n",
        "        if moderation == 'Flagged':\n",
        "            print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "            break\n",
        "\n",
        "        if top_3_laptops is None:\n",
        "            conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            response_assistant = get_chat_model_completions(conversation)\n",
        "\n",
        "            moderation = moderation_check(response_assistant)\n",
        "            if moderation == 'Flagged':\n",
        "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                break\n",
        "\n",
        "            confirmation = intent_confirmation_layer(response_assistant)\n",
        "\n",
        "            moderation = moderation_check(confirmation)\n",
        "            if moderation == 'Flagged':\n",
        "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                break\n",
        "\n",
        "            if \"No\" in confirmation:\n",
        "                conversation.append({\"role\": \"assistant\", \"content\": response_assistant})\n",
        "                print(\"\\n\" + response_assistant + \"\\n\")\n",
        "                print('\\n' + confirmation + '\\n')\n",
        "            else:\n",
        "                print(\"\\n\" + response_assistant + \"\\n\")\n",
        "                print('\\n' + confirmation + '\\n')\n",
        "                response = dictionary_present(response_assistant)\n",
        "\n",
        "                moderation = moderation_check(response)\n",
        "                if moderation == 'Flagged':\n",
        "                    print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                    break\n",
        "\n",
        "                print('\\n' + response + '\\n')\n",
        "                print(\"Thank you for providing all the information. Kindly wait, while I fetch the products: \\n\")\n",
        "                top_3_laptops = compare_laptops_with_user(response)\n",
        "\n",
        "                validated_reco = recommendation_validation(top_3_laptops)\n",
        "\n",
        "                if len(validated_reco) == 0:\n",
        "                    print(\"Sorry, we do not have laptops that match your requirements. Connecting you to a human expert.\")\n",
        "                    break\n",
        "\n",
        "                conversation_reco = initialize_conv_reco(validated_reco)\n",
        "                recommendation = get_chat_model_completions(conversation_reco)\n",
        "\n",
        "                moderation = moderation_check(recommendation)\n",
        "                if moderation == 'Flagged':\n",
        "                    print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                    break\n",
        "\n",
        "                conversation_reco.append({\"role\": \"user\", \"content\": \"This is my user profile\" + response})\n",
        "\n",
        "                conversation_reco.append({\"role\": \"assistant\", \"content\": recommendation})\n",
        "\n",
        "                print(recommendation + '\\n')\n",
        "\n",
        "        else:\n",
        "            conversation_reco.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            response_asst_reco = get_chat_model_completions(conversation_reco)\n",
        "\n",
        "            moderation = moderation_check(response_asst_reco)\n",
        "            if moderation == 'Flagged':\n",
        "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                break\n",
        "\n",
        "            print('\\n' + response_asst_reco + '\\n')\n",
        "            conversation.append({\"role\": \"assistant\", \"content\": response_asst_reco})"
      ],
      "metadata": {
        "id": "TrPeNDjgsi2w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Areas of Improvement and Final Comments**"
      ],
      "metadata": {
        "id": "j7bm2GWRsnYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamer_conversation = [{\"role\":\"assistant\",\"content\":\"Hi there! I'm an intelligent laptop gadget expert and I'm here to help you find the best laptop for your needs. Please tell me a little bit about yourself and your requirements so that I can assist you better.\"},\n",
        "{\"role\":\"user\",\"content\":\"Yes, I prefer gaming with my graphics at high setting\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for letting me know. Based on your preference for high graphics settings, I would recommend a laptop with a high GPU intensity. This will ensure that you can enjoy your games with excellent visual quality. Now, I have a question to better understand your needs. Are you primarily looking for a laptop that you can easily carry around and game on the go, or do you mainly use it in a stationary location?\"},\n",
        "{\"role\":\"user\",\"content\":\"I prefer using my laptop at a stationary location\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for providing that information. Since you primarily use your laptop in a stationary location, portability may not be a top priority for you. Now, I have one more question to help me understand your requirements better. Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"},\n",
        "{\"role\":\"user\",\"content\":\"150000\"}\n",
        "]\n",
        "\n",
        "gamer_conversation_initialize = initialize_conversation()\n",
        "gamer_conversation_initialize.extend(gamer_conversation)\n",
        "gamer_conversation_assistant_output = get_chat_model_completions(gamer_conversation_initialize)\n",
        "gamer_response_dict = dictionary_present(gamer_conversation_assistant_output)\n",
        "gamer_dict = extract_dictionary_from_string(gamer_response_dict)\n",
        "print(gamer_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54nHv2RusvRn",
        "outputId": "30d103d0-dd46-43cc-c7af-553623477175"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'high', 'display quality': 'high', 'portability': 'low', 'multitasking': 'high', 'processing speed': 'high', 'budget': '150000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamer_tagged_dict = {'gpu intensity': 'high', 'display quality': 'high', 'portability': 'low', 'multitasking': 'high', 'processing speed': 'high', 'budget': '150000'}\n",
        "print(gamer_tagged_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uljILysPs1e7",
        "outputId": "16f1ea80-bc8d-4545-91ea-b190284cf786"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'high', 'display quality': 'high', 'portability': 'low', 'multitasking': 'high', 'processing speed': 'high', 'budget': '150000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "academic_conversation = [{\"role\":\"assistant\",\"content\":\"Hi there! I'm an intelligent laptop gadget expert and I'm here to help you find the best laptop for your needs. Please tell me a little bit about yourself and your requirements so that I can assist you better.\"},\n",
        "{\"role\":\"user\",\"content\":\"i am a student and i'm looking to buy some laptops\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Great! As a student, you likely have specific requirements for a laptop that will support your academic needs. Could you please provide me with more information about your requirements? Are you looking for a laptop for general use, such as browsing the internet, taking notes, and writing assignments? Or do you have any specific software or tasks that you need the laptop to handle? Understanding your needs will help me recommend the best laptop for you.\"},\n",
        "{\"role\":\"user\",\"content\":\"I am working as a academic researcher and I do work with softwares and programming languages such as Matlab, Python and CATIA\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for providing that information. As an academic researcher, you require a laptop that can handle software and programming tasks efficiently. May I know if you work with large datasets or perform any intensive computations? Understanding the nature of your work will help me determine the processing power and multitasking capabilities needed for your laptop.\"},\n",
        "{\"role\":\"user\",\"content\":\"Yes, occasionally. I'm currently also working on a project on computer vision\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for sharing that. Working on computer vision projects can be resource-intensive, especially when dealing with large datasets and complex algorithms. It requires a laptop with high processing power and a capable graphics card. Do you also require a high-quality display for accurate visualization of images and videos? Additionally, do you prioritize portability, as you may need to work on your projects in different locations?\"},\n",
        "{\"role\":\"user\",\"content\":\"I need a decent display and I also carry my laptop to college and conferences\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Understood. Based on your requirements as an academic researcher working with software and programming languages like Matlab, Python, and CATIA, as well as computer vision projects, I would recommend the following specifications for your laptop: - GPU intensity: High (for handling computer vision tasks) - Display quality: Medium (for decent display) - Portability: Medium (since you carry your laptop to college and conferences) - Multitasking: High (to handle multiple software and programming tasks) - Processing speed: High (for efficient computation) Now, I need to know your budget for the laptop. Could you please let me know your maximum budget in INR?\"},\n",
        "{\"role\":\"user\",\"content\":\"approximately 100000\"}\n",
        "]\n",
        "\n",
        "academic_conversation_initialize = initialize_conversation()\n",
        "academic_conversation_initialize.extend(academic_conversation)\n",
        "academic_conversation_assistant_output = get_chat_model_completions(academic_conversation_initialize)\n",
        "academic_response_dict = dictionary_present(academic_conversation_assistant_output)\n",
        "academic_dict = extract_dictionary_from_string(academic_response_dict)\n",
        "print(academic_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azu7mWmms7kE",
        "outputId": "0861aac7-3921-402b-b0b3-8898fc9576ad"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'high', 'display quality': 'medium', 'portability': 'medium', 'multitasking': 'high', 'processing speed': 'high', 'budget': '100000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "academic_tagged_dict = {'gpu intensity': 'high', 'display quality': 'medium', 'portability': 'medium', 'multitasking': 'medium', 'processing speed': 'high', 'budget': '100000'}\n",
        "print(academic_tagged_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnHRTO5YtBOi",
        "outputId": "6289ff5a-421c-4c6d-d89c-a0471f1c876a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'high', 'display quality': 'medium', 'portability': 'medium', 'multitasking': 'medium', 'processing speed': 'high', 'budget': '100000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "business_conversation = [\n",
        "{\"role\":\"assistant\",\"content\":\"Hi there! I'm an intelligent laptop gadget expert and I'm here to help you find the best laptop for your needs. Please tell me a little bit about yourself and your requirements so that I can assist you better.\"},\n",
        "{\"role\":\"user\",\"content\":\"Hi. I a a business executive. I'm in the market to buy a laptop that fits my needs\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Great! As a business executive, having a reliable and efficient laptop is crucial for your work. May I know what kind of tasks you primarily focus on? Are you involved in tasks such as data analysis, presentations, or multitasking between various applications? Understanding your specific work requirements will help me recommend the best laptop for you. \"},\n",
        "{\"role\":\"user\",\"content\":\"I'll use my laptop for day-to-day work such as attending zoom calls with clients, preparting reports and doing market research. I also do analysis on Excel\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for providing that information. Based on your work requirements, it seems like you need a laptop that can handle multitasking, has good processing speed, and a decent display quality for presentations and data analysis. Portability may not be a top priority since you mentioned that you primarily work from a stationary location. Do you have any specific preferences or requirements for the graphics performance of the laptop?\"},\n",
        "{\"role\":\"user\",\"content\":\"I require a highly portable machine as I'll be commuting to work and also travelling to client locations. Graphics is not a priority for me\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Understood. In that case, a laptop with high portability and multitasking capabilities would be ideal for you. Since graphics performance is not a priority, we can focus more on processing speed and display quality. Do you have any specific budget in mind for your laptop purchase? Knowing your budget will help me find options that fit within your price range while meeting your specified requirements.\"},\n",
        "{\"role\":\"user\",\"content\":\"No budget is not a constraint. choose the best\"},\n",
        "{\"role\":\"assistant\",\"content\":\"Thank you for letting me know. In that case, I will recommend a laptop with high processing speed, good display quality, and excellent portability. This will ensure that you can efficiently handle your day-to-day work tasks, attend Zoom calls, prepare reports, and perform market research without any performance issues. Here are the specifications for the laptop I recommend for you: - GPU intensity: Low - Display quality: High - Portability: High - Multitasking: High - Processing speed: High - Budget: Not specified Please note that the budget is not specified as you mentioned that it is not a constraint. However, if you have any specific budget in mind, please let me know and I can provide you with more tailored recommendations.\"},\n",
        "{\"role\":\"user\",\"content\":\"okay. maximum 200000\"}\n",
        "]\n",
        "\n",
        "business_conversation_initialize = initialize_conversation()\n",
        "business_conversation_initialize.extend(business_conversation)\n",
        "business_conversation_assistant_output = get_chat_model_completions(business_conversation_initialize)\n",
        "business_response_dict = dictionary_present(business_conversation_assistant_output)\n",
        "business_dict = extract_dictionary_from_string(business_response_dict)\n",
        "print(business_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z60I64X9tGX_",
        "outputId": "84d3178b-c373-4996-c740-ac1bd56b4697"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'low', 'display quality': 'high', 'portability': 'high', 'multitasking': 'high', 'processing speed': 'high', 'budget': '200000 inr'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "business_tagged_dict = {'gpu intensity': 'low', 'display quality': 'high', 'portability': 'high', 'multitasking': 'high', 'processing speed': 'high', 'budget': '200000'}\n",
        "print(business_tagged_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iHpgR4htMX6",
        "outputId": "6c7b0653-ebba-42d9-c309-83de63347b1f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu intensity': 'low', 'display quality': 'high', 'portability': 'high', 'multitasking': 'high', 'processing speed': 'high', 'budget': '200000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_response(tagged_dict, model_dict):\n",
        "  score = 0\n",
        "  mappings = {\n",
        "      'low': 0,\n",
        "      'medium': 1,\n",
        "      'high': 2\n",
        "  }\n",
        "\n",
        "  for key in tagged_dict.keys():\n",
        "    if key == 'budget':\n",
        "      continue\n",
        "    tagged_value = tagged_dict[key]\n",
        "    model_value = model_dict[key]\n",
        "    tagged_mapping = mappings.get(tagged_value, -1)\n",
        "    model_mapping = mappings.get(model_value, -1)\n",
        "\n",
        "    if model_mapping >= tagged_mapping:\n",
        "        score += 1\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "v0RyIIT6tRLJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamer_score = evaluate_model_response(gamer_tagged_dict,gamer_dict)\n",
        "print(gamer_score)\n",
        "academic_score = evaluate_model_response(academic_tagged_dict,academic_dict)\n",
        "print(academic_score)\n",
        "business_score = evaluate_model_response(business_tagged_dict,business_dict)\n",
        "print(business_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OttBQ_hwtWrJ",
        "outputId": "ef1c4f05-a1b9-486a-a177-3608ab4c12a7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that for gamer, the model is not able to perform well. But for the academic and business persona, it is able to."
      ],
      "metadata": {
        "id": "s3dACzzYtcFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future Scope of Work**"
      ],
      "metadata": {
        "id": "99C_o_iitfW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The output format of each layer is inconsistent. You can use the function API capability of GPT to instruct the output format as per the input request.\n",
        "2. The rule framework provided to classify each laptop’s specification is not exhaustive. You can expand the rules to give a comprehensive context to the LLM.\n",
        "3. There are misclassifications in the laptop’s specifications, even after specifying clear rules for LLM. You can fine-tune an open-source LLM to make its understanding & performance better.\n",
        "4. Once the products are extracted, the dialogue flow doesn’t allow recalling of product extraction if there is any intent change. You can add another layer to observe any request for a change in the user intent and then use this flag to recall the product extraction based on the updated intent.\n",
        "5. As an alternative & simple solution, you can use vector embeddings of each product and compare it with the user intent to find the most relevant products.\n",
        "6. You can template this workflow/solution to build a chatbot for any product domain. Note: You must add the relevant domain expertise/rules to give the LLM context understanding."
      ],
      "metadata": {
        "id": "LX6fCwomtj-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT_MODEL = \"gpt-3.5-turbo-instruct\"\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "#GPT_MODEL = \"gpt-4o\"\n",
        "\n",
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
        "    try:\n",
        "        # client = openai.ChatCompletion.create(\n",
        "        #     model=model,\n",
        "        #     messages=messages,\n",
        "        #     tools=tools,\n",
        "        #     tool_choice=tool_choice,\n",
        "        # )\n",
        "        response =  openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=tool_choice,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ],
      "metadata": {
        "id": "RQ0MBIALt0K9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
      ],
      "metadata": {
        "id": "T5cHKziht7bU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_laptop_details\",\n",
        "            \"description\": \"Get the best selling laptop\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"model\" : {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Laptop model e.g. Lenovo LOQ \",\n",
        "                    },\n",
        "                   \"processors\":{\n",
        "                       \"type\": \"string\",\n",
        "                       \"description\": \"processor in laptop e.g. Intel Core \",\n",
        "                   }\n",
        "\n",
        "                },\n",
        "                \"required\": [\"model\",\"processors\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "aYicbnPUuCJL"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\":\"What is the latest Tech news\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "chat_response\n",
        "assistant_message = chat_response.choices[0].message\n",
        "messages.append(assistant_message)\n",
        "assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWyGCeBauHle",
        "outputId": "c5a8859c-ead8-43de-ec87-cd5a5938d36b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c6317e0dc10> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": \"I don't have real-time access to the latest news. However, I can assist you with information or specific queries you may have. How can I help you today?\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"user\", \"content\":\" Effect of Laptop Heat on Human Body\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "assistant_message = chat_response.choices[0].message\n",
        "messages.append(assistant_message)\n",
        "assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FzlmdMquOkI",
        "outputId": "e59f9c9c-4c30-4952-93e5-e1614d8ab79a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c6317e38720> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": \"Excessive heat generated by laptops can have potential health effects on the human body if not managed properly. Here are some common issues related to laptop heat:\\n\\n1. **Skin Burns**: Direct contact with a hot laptop surface can cause skin burns or irritation, especially if the laptop is used on bare skin for extended periods.\\n\\n2. **Overheating**: Laptops that generate a lot of heat may lead to overheating, which can cause discomfort and potentially reduce fertility in men if the laptop is placed on the lap for extended periods.\\n\\n3. **Decreased Fertility**: Prolonged exposure to the heat from a laptop on the lap has been linked to decreased sperm production in men due to increased scrotal temperature.\\n\\n4. **Discomfort**: Excessive heat from the laptop can cause discomfort, sweating, and fatigue, making it harder to concentrate and work efficiently.\\n\\nTo mitigate these effects, consider the following suggestions:\\n\\n- Use a laptop stand or cooling pad to improve airflow and reduce heat buildup.\\n- Avoid placing the laptop directly on your lap for extended periods. Use a desk or table instead.\\n- Take breaks and allow your laptop to cool down if it feels excessively hot.\\n- Clean the laptop vents and fans regularly to ensure proper ventilation.\\n\\nIt's essential to be mindful of the heat generated by laptops and take necessary precautions to protect your health and well-being.\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[]\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "#messages.append({\"role\": \"user\", \"content\": \"List Laptops that cost less than 50000  in Pune, India \"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Positive Effect of Laptop \"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "chat_response\n",
        "assistant_message = chat_response.choices[0].message\n",
        "messages.append(assistant_message)\n",
        "assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iSc_HAZuVG8",
        "outputId": "f5bedc06-9689-4eee-d913-d81181ac01a5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c6317df3e20> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": \"Could you please specify which positive effect of laptops you are interested in learning about?\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[]\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Which processor does Lenovo have?\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "chat_response\n",
        "assistant_message = chat_response.choices[0].message\n",
        "messages.append(assistant_message)\n",
        "assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jIlHR2mxgWP",
        "outputId": "b7197baf-379a-4d9c-852e-cded42e0f11f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c6317df3f10> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": \"Which Lenovo model are you referring to?\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[]\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What processor does a Lenovo ThinkPad have?\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "chat_response\n",
        "# assistant_message = chat_response.choices[0].message\n",
        "# messages.append(assistant_message)\n",
        "# assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzFnevunxrN0",
        "outputId": "aab92bbe-1189-4ee8-bb38-1909900d8923"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-9lyXlVSF2gJXBE0AIL5ABcYSl4vpv at 0x7c6318532ed0> JSON: {\n",
              "  \"id\": \"chatcmpl-9lyXlVSF2gJXBE0AIL5ABcYSl4vpv\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1721221173,\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": null,\n",
              "        \"tool_calls\": [\n",
              "          {\n",
              "            \"id\": \"call_nVOO4XLwDGGGX6AbGZ9FP1yd\",\n",
              "            \"type\": \"function\",\n",
              "            \"function\": {\n",
              "              \"name\": \"get_laptop_details\",\n",
              "              \"arguments\": \"{\\\"model\\\":\\\"Lenovo ThinkPad\\\",\\\"processors\\\":\\\"\\\"}\"\n",
              "            }\n",
              "          }\n",
              "        ]\n",
              "      },\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"tool_calls\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 102,\n",
              "    \"completion_tokens\": 22,\n",
              "    \"total_tokens\": 124\n",
              "  },\n",
              "  \"system_fingerprint\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[]\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Does Dell have intel core i7 processor?\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "chat_response\n",
        "# assistant_message = chat_response.choices[0].message\n",
        "# messages.append(assistant_message)\n",
        "# assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J8XwzoyxxUw",
        "outputId": "9e041442-0855-4575-c907-5543237ad559"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-9lyYAZu5GcIXxmDL853gXc7OTLRPN at 0x7c63475602c0> JSON: {\n",
              "  \"id\": \"chatcmpl-9lyYAZu5GcIXxmDL853gXc7OTLRPN\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1721221198,\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": null,\n",
              "        \"tool_calls\": [\n",
              "          {\n",
              "            \"id\": \"call_6KocckY7pQG7rla7vQ7xjGGD\",\n",
              "            \"type\": \"function\",\n",
              "            \"function\": {\n",
              "              \"name\": \"get_laptop_details\",\n",
              "              \"arguments\": \"{\\\"model\\\":\\\"Dell\\\",\\\"processors\\\":\\\"Intel Core i7\\\"}\"\n",
              "            }\n",
              "          }\n",
              "        ]\n",
              "      },\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"tool_calls\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 102,\n",
              "    \"completion_tokens\": 24,\n",
              "    \"total_tokens\": 126\n",
              "  },\n",
              "  \"system_fingerprint\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT_MODEL = \"gpt-3.5-turbo-instruct\"\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "#GPT_MODEL = \"gpt-4o\"\n",
        "\n",
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request2(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
        "    try:\n",
        "        response =  openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_grahics\"}},\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ],
      "metadata": {
        "id": "Oq6OfMAix28a"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools2 = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_grahics\",\n",
        "            \"description\": \"Get the laptops with specified Graphics\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"graphics\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"graphics\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"graphics\"],\n",
        "            },\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_ram\",\n",
        "            \"description\": \"Get Ram size of a specific model\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"model\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"model, e.g. Lenovo t-40\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"model\"]\n",
        "            },\n",
        "        }\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "ACQp_PfVx-Ub"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forcing the use of specific functions or no function\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\":\"which laptops have Nvidia GeoforceRTX configured?\"})\n",
        "chat_response = chat_completion_request2(\n",
        "    messages, tools=tools2\n",
        ")\n",
        "chat_response\n",
        "assistant_message = chat_response.choices[0].message\n",
        "messages.append(assistant_message)\n",
        "assistant_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGaVaw2KyE1N",
        "outputId": "458c24dd-dd9d-4387-aab9-3013f685228c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c6317e0e200> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"tool_calls\": [\n",
              "    {\n",
              "      \"id\": \"call_FEaJeTt3dfOPLm3VhE1ttDTC\",\n",
              "      \"type\": \"function\",\n",
              "      \"function\": {\n",
              "        \"name\": \"get_grahics\",\n",
              "        \"arguments\": \"{\\\"graphics\\\":\\\"Nvidia GeoforceRTX\\\"}\"\n",
              "      }\n",
              "    }\n",
              "  ]\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}